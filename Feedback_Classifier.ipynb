{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in ./myenv/lib/python3.12/site-packages (4.48.1)\n",
      "Requirement already satisfied: filelock in ./myenv/lib/python3.12/site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in ./myenv/lib/python3.12/site-packages (from transformers) (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./myenv/lib/python3.12/site-packages (from transformers) (2.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./myenv/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./myenv/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./myenv/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in ./myenv/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./myenv/lib/python3.12/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./myenv/lib/python3.12/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./myenv/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./myenv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./myenv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./myenv/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./myenv/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./myenv/lib/python3.12/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./myenv/lib/python3.12/site-packages (from requests->transformers) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dead255bacd74f0aa4e314a8badf17c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "316ecd9a41ce42dfaeea518bbadaa34f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19a12e7e8f294037b85b28c3d182194e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "154826c3f0cb4b188a243d4bba41d049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fafa062169e47738cb4d728f1f612c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "692f6c7bffb141d9bc189c5ac81997e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0880ec65ecde455d800b32859cbf9176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilGPT-2 loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the model and tokenizer\n",
    "model_name = \"distilgpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "print(\"DistilGPT-2 loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Feedback          Category\n",
      "7    The video avoided unnecessary jargon, which I ...   Content Clarity\n",
      "105  The visuals and animations made the content mo...        Engagement\n",
      "117  I liked how the speaker used humor to make the...        Engagement\n",
      "173  The examples were well-chosen and directly tie...         Relevance\n",
      "53   I loved how the speaker repeated important ide...   Content Clarity\n",
      "86   I appreciated how the video compared similar i...   Content Clarity\n",
      "132  The conversational tone of the video made it f...        Engagement\n",
      "127  The use of real-world examples made the video ...        Engagement\n",
      "247  There were constant buffering issues during th...  Technical Issues\n",
      "110  The pacing of the video kept it interesting wi...        Engagement\n",
      "164  The speaker related the content to commonly fa...         Relevance\n",
      "287  The text on the visuals was blurry and hard to...  Technical Issues\n",
      "31   The consistent use of terminology made the con...   Content Clarity\n",
      "87   The explanations were clear, and the examples ...   Content Clarity\n",
      "20   The transitions between topics were smooth and...   Content Clarity\n",
      "19   It was great that the speaker repeated the mos...   Content Clarity\n",
      "206  The speaker balanced speed and clarity perfectly.            Pacing\n",
      "48   The content was presented in a clear and logic...   Content Clarity\n",
      "121  The presenter’s enthusiasm was contagious and ...        Engagement\n",
      "227  The speaker’s slow and deliberate explanations...            Pacing\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "json_file_path = 'feedback_comments.json'\n",
    "\n",
    "# Check if the file exists\n",
    "if not os.path.exists(json_file_path):\n",
    "    raise FileNotFoundError(f\"The file at {json_file_path} does not exist.\")\n",
    "\n",
    "# Check if the file is not empty\n",
    "if os.path.getsize(json_file_path) == 0:\n",
    "    raise ValueError(f\"The file at {json_file_path} is empty.\")\n",
    "\n",
    "# Read and print the content of the file\n",
    "with open(json_file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "    # print(\"File content:\")\n",
    "    # print(content)\n",
    "\n",
    "try:\n",
    "    df = pd.read_json(json_file_path)\n",
    "except ValueError as e:\n",
    "    raise ValueError(f\"Error reading JSON file: {e}\")\n",
    "\n",
    "print(df.sample(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Apply cleaning\n",
    "df['Cleaned_Feedback'] = df['Feedback'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/pouyasmac/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Cleaned_Feedback  \\\n",
      "0       the explanation was clear and easy to follow   \n",
      "1  i understood the topic much better after watch...   \n",
      "2  the concepts were wellexplained with simple la...   \n",
      "3  the speaker broke down complex ideas into mana...   \n",
      "4  i appreciate how the examples made the content...   \n",
      "\n",
      "                                  Tokenized_Feedback  \n",
      "0  [the, explanation, was, clear, and, easy, to, ...  \n",
      "1  [i, understood, the, topic, much, better, afte...  \n",
      "2  [the, concepts, were, wellexplained, with, sim...  \n",
      "3  [the, speaker, broke, down, complex, ideas, in...  \n",
      "4  [i, appreciate, how, the, examples, made, the,...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load SpaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Tokenize function using SpaCy\n",
    "def spacy_tokenizer(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.text for token in doc]\n",
    "\n",
    "# Apply tokenization to the 'Cleaned_Feedback' column\n",
    "df['Tokenized_Feedback'] = df['Cleaned_Feedback'].apply(spacy_tokenizer)\n",
    "\n",
    "# Display tokenized feedback\n",
    "print(df[['Cleaned_Feedback', 'Tokenized_Feedback']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Load the local LLM\n",
    "model_name = \"distilgpt2\"  # Replace with your local LLM model name\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_prompt(feedback):\n",
    "    return (f\"Classify the following feedback into one of the categories:\\n\"\n",
    "            f\"Feedback: \\\"{feedback}\\\"\\n\"\n",
    "            f\"Categories: Content Clarity, Engagement, Relevance, Pacing, Technical Issues.\\n\"\n",
    "            f\"Answer:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_feedback(feedback):\n",
    "    # Construct the prompt\n",
    "    prompt = construct_prompt(feedback)\n",
    "\n",
    "    # Tokenize the input\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "    # Generate output with max_new_tokens\n",
    "    outputs = model.generate(\n",
    "        inputs.input_ids,\n",
    "        max_new_tokens=20,  # Limit only the generated output to 20 tokens\n",
    "        temperature=0.7,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        pad_token_id=tokenizer.pad_token_id\n",
    "    )\n",
    "\n",
    "    # Decode the output\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Extract the category from the response\n",
    "    category = response.split(\"Answer:\")[-1].strip()\n",
    "    return category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Feedback  \\\n",
      "0      The explanation was clear and easy to follow.   \n",
      "1  I understood the topic much better after watch...   \n",
      "2  The concepts were well-explained, with simple ...   \n",
      "3  The speaker broke down complex ideas into mana...   \n",
      "4  I appreciate how the examples made the content...   \n",
      "\n",
      "                              LLM_Predicted_Category  \n",
      "0                     \"The answer was clear and easy  \n",
      "1  \"I understand the topic much better after watc...  \n",
      "2                                 \"The concepts were  \n",
      "3  \"The speaker broke down complex ideas into man...  \n",
      "4  \"I appreciate how the examples made the conten...  \n"
     ]
    }
   ],
   "source": [
    "# Apply classification function to each feedback in the DataFrame\n",
    "df['LLM_Predicted_Category'] = df['Feedback'].apply(classify_feedback)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df[['Feedback', 'LLM_Predicted_Category']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
